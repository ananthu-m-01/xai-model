"""
Dynamic AI Explanation Generator for Research
==========================================
Generates genuine AI explanations by passing model outputs and patient data 
to language models without any hardcoded templates.
"""

import json
import csv
from typing import Dict, Any, List
from datetime import datetime
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DynamicAIExplainer:
    """
    Generates explanations using actual language models without hardcoded content.
    """
    
    def __init__(self):
        """Initialize with available language models."""
        self.explanation_model = None
        self.tokenizer = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Try to load a medical language model for explanations
        self._load_explanation_model()
    
    def _load_explanation_model(self):
        """Load an available language model for generating explanations."""
        
        # List of models to try (from most specific to most general)
        model_candidates = [
            "microsoft/DialoGPT-medium",  # Conversational model
            "gpt2",  # Fallback general model
            "distilgpt2"  # Lightweight fallback
        ]
        
        for model_name in model_candidates:
            try:
                logger.info(f"Attempting to load {model_name}...")
                self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.explanation_model = AutoModelForCausalLM.from_pretrained(
                    model_name,
                    torch_dtype=torch.float16 if self.device.type == 'cuda' else torch.float32
                )
                
                # Set pad token
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                
                logger.info(f"‚úÖ Successfully loaded {model_name}")
                return True
                
            except Exception as e:
                logger.warning(f"Failed to load {model_name}: {e}")
                continue
        
        logger.warning("Could not load any language model. Will use structured data analysis.")
        return False
    
    def generate_explanation(self, patient_data: Dict, model_prediction: Dict) -> Dict[str, Any]:
        """
        Generate explanation by analyzing data and using AI models.
        
        Args:
            patient_data: Raw patient clinical data
            model_prediction: Model's prediction output
        
        Returns:
            AI-generated explanation
        """
        
        # Create structured clinical context
        clinical_context = self._extract_clinical_context(patient_data, model_prediction)
        
        # Generate AI explanations if model available
        if self.explanation_model and self.tokenizer:
            ai_explanations = self._generate_ai_explanations(clinical_context)
        else:
            ai_explanations = self._generate_analysis_based_explanation(clinical_context)
        
        return {
            'participant_id': patient_data.get('participant_id'),
            'clinical_context': clinical_context,
            'ai_explanations': ai_explanations,
            'generation_method': 'Language Model' if self.explanation_model else 'Clinical Analysis',
            'timestamp': datetime.now().isoformat()
        }
    
    def _extract_clinical_context(self, patient_data: Dict, model_prediction: Dict) -> Dict[str, Any]:
        """Extract and structure clinical context from raw data."""
        
        def safe_float(value, default=0):
            try:
                return float(value or default)
            except (ValueError, TypeError):
                return default
        
        # Extract key clinical variables
        context = {
            'demographics': {
                'age': safe_float(patient_data.get('age'), 60),
                'sex': 'Female' if str(patient_data.get('sex', '')).strip() == '0' else 'Male',
                'education_years': safe_float(patient_data.get('education'), 3)
            },
            'cognitive_assessments': {
                'memory_score': safe_float(patient_data.get('CVLT_7'), 13.5),
                'fluid_intelligence': safe_float(patient_data.get('RPM'), 50),
                'depression_score': safe_float(patient_data.get('BDI'), 5)
            },
            'risk_factors': {
                'family_dementia_history': safe_float(patient_data.get('dementia_history_parents'), 0) > 0,
                'apoe_genotype': patient_data.get('APOE_haplotype', 'Unknown')
            },
            'biomarkers': {
                'total_cholesterol': safe_float(patient_data.get('total_cholesterol')),
                'hdl_cholesterol': safe_float(patient_data.get('cholesterol_HDL')),
                'bmi': safe_float(patient_data.get('BMI'))
            },
            'model_assessment': {
                'predicted_risk': model_prediction.get('predicted_risk'),
                'confidence': model_prediction.get('confidence', 0),
                'actual_label': model_prediction.get('actual_label'),
                'prediction_agreement': model_prediction.get('agreement', False)
            }
        }
        
        return context
    
    def _generate_ai_explanations(self, clinical_context: Dict) -> Dict[str, Any]:
        """Generate explanations using the loaded language model."""
        
        explanations = {}
        
        # Generate different types of explanations
        for explanation_type in ['clinical_analysis', 'patient_summary', 'technical_assessment']:
            prompt = self._create_dynamic_prompt(clinical_context, explanation_type)
            
            try:
                generated_text = self._query_language_model(prompt)
                explanations[explanation_type] = {
                    'content': generated_text,
                    'prompt_used': prompt[:100] + "...",  # Store prompt snippet for transparency
                    'generated_by': 'AI Language Model'
                }
            except Exception as e:
                logger.error(f"Error generating {explanation_type}: {e}")
                explanations[explanation_type] = {
                    'content': f"Error generating explanation: {str(e)}",
                    'generated_by': 'Error'
                }
        
        return explanations
    
    def _create_dynamic_prompt(self, clinical_context: Dict, explanation_type: str) -> str:
        """Create dynamic prompts based on actual data."""
        
        demo = clinical_context['demographics']
        cog = clinical_context['cognitive_assessments']
        risk = clinical_context['risk_factors']
        model = clinical_context['model_assessment']
        
        if explanation_type == 'clinical_analysis':
            prompt = f"Analyze this cognitive assessment case: {demo['age']}yo {demo['sex']}, "
            prompt += f"Memory score: {cog['memory_score']}, Intelligence: {cog['fluid_intelligence']}, "
            prompt += f"Depression: {cog['depression_score']}, Family history: {risk['family_dementia_history']}, "
            prompt += f"AI predicts: {model['predicted_risk']} with {model['confidence']:.1%} confidence. "
            prompt += "Provide clinical interpretation:"
            
        elif explanation_type == 'patient_summary':
            prompt = f"Explain to a {demo['age']}-year-old {demo['sex'].lower()} patient: "
            prompt += f"Your memory test score is {cog['memory_score']}, thinking skills {cog['fluid_intelligence']}, "
            prompt += f"mood score {cog['depression_score']}. AI assessment shows {model['predicted_risk']}. "
            prompt += "Explain in simple terms what this means:"
            
        else:  # technical_assessment
            prompt = f"Technical analysis: Subject {demo['age']}y, cognitive profile "
            prompt += f"CVLT-7={cog['memory_score']}, RPM={cog['fluid_intelligence']}, BDI={cog['depression_score']}, "
            prompt += f"FamHx={risk['family_dementia_history']}, Model output: {model['predicted_risk']} "
            prompt += f"(conf={model['confidence']:.3f}). Detailed assessment:"
        
        return prompt
    
    def _query_language_model(self, prompt: str, max_length: int = 200) -> str:
        """Query the language model with the prompt."""
        
        try:
            # Tokenize input
            inputs = self.tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=512)
            
            # Generate response
            with torch.no_grad():
                outputs = self.explanation_model.generate(
                    inputs,
                    max_length=len(inputs[0]) + max_length,
                    temperature=0.8,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    no_repeat_ngram_size=3,
                    repetition_penalty=1.1
                )
            
            # Decode and extract generated part
            full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            generated_part = full_text[len(prompt):].strip()
            
            return generated_part if generated_part else "Model did not generate additional content."
            
        except Exception as e:
            logger.error(f"Error querying language model: {e}")
            return f"Language model error: {str(e)}"
    
    def _generate_analysis_based_explanation(self, clinical_context: Dict) -> Dict[str, Any]:
        """Generate explanations based on clinical data analysis when no language model available."""
        
        demo = clinical_context['demographics']
        cog = clinical_context['cognitive_assessments']
        risk = clinical_context['risk_factors']
        model = clinical_context['model_assessment']
        
        # Analyze patterns in the data
        memory_z_score = (cog['memory_score'] - 13.5) / 3.0  # Rough normalization
        intelligence_z_score = (cog['fluid_intelligence'] - 50) / 15.0
        
        # Generate based on actual data patterns
        clinical_findings = []
        
        if memory_z_score < -0.5:
            clinical_findings.append(f"Memory performance {cog['memory_score']} indicates potential concern")
        elif memory_z_score > 0.5:
            clinical_findings.append(f"Memory performance {cog['memory_score']} is above average")
        
        if intelligence_z_score > 1.0:
            clinical_findings.append(f"High fluid intelligence {cog['fluid_intelligence']} suggests cognitive resilience")
        elif intelligence_z_score < -1.0:
            clinical_findings.append(f"Lower fluid intelligence {cog['fluid_intelligence']} may indicate vulnerability")
        
        if cog['depression_score'] > 15:
            clinical_findings.append(f"Depression score {cog['depression_score']} requires attention")
        
        if risk['family_dementia_history']:
            clinical_findings.append("Positive family history increases genetic risk")
        
        # Generate explanation based on findings
        clinical_analysis = f"Analysis of {demo['age']}-year-old {demo['sex']}: " + ". ".join(clinical_findings)
        clinical_analysis += f". AI model assessment: {model['predicted_risk']} with {model['confidence']:.1%} confidence."
        
        # Patient explanation
        risk_level = "higher" if model['predicted_risk'] == 'HIGH RISK' else "lower"
        patient_summary = f"Your brain health assessment shows {risk_level} risk. "
        patient_summary += f"Key factors: memory score {cog['memory_score']}, thinking skills {cog['fluid_intelligence']}. "
        patient_summary += f"The AI is {model['confidence']:.0%} confident in this assessment."
        
        # Technical assessment
        technical_assessment = f"Cognitive profile analysis: Memory z-score {memory_z_score:.2f}, "
        technical_assessment += f"Intelligence z-score {intelligence_z_score:.2f}. "
        technical_assessment += f"Risk stratification: {model['predicted_risk']} (confidence {model['confidence']:.3f}). "
        technical_assessment += f"Clinical correlation: {len(clinical_findings)} significant findings identified."
        
        return {
            'clinical_analysis': {
                'content': clinical_analysis,
                'generated_by': 'Clinical Data Analysis',
                'findings_count': len(clinical_findings)
            },
            'patient_summary': {
                'content': patient_summary,
                'generated_by': 'Patient-Focused Analysis'
            },
            'technical_assessment': {
                'content': technical_assessment,
                'generated_by': 'Technical Analysis',
                'z_scores': {
                    'memory': memory_z_score,
                    'intelligence': intelligence_z_score
                }
            }
        }

def process_research_explanations(max_participants: int = 5) -> Dict[str, Any]:
    """
    Process explanations for research using dynamic AI generation.
    """
    
    print("üî¨ DYNAMIC AI EXPLANATION GENERATOR (RESEARCH)")
    print("=" * 60)
    print("Generating genuine AI explanations without hardcoded content")
    print()
    
    # Initialize dynamic explainer
    explainer = DynamicAIExplainer()
    
    # Load data
    try:
        with open("participants_with_labels.csv", 'r', encoding='utf-8') as f:
            participants = list(csv.DictReader(f))
        
        with open("results/real_dataset_explanation_summary.json", 'r') as f:
            model_results = json.load(f)
        
        print(f"‚úÖ Loaded {len(participants)} participants and model results")
    except Exception as e:
        print(f"‚ùå Error loading data: {e}")
        return {}
    
    # Process participants
    research_results = {
        'metadata': {
            'generation_timestamp': datetime.now().isoformat(),
            'model_available': explainer.explanation_model is not None,
            'explanation_method': 'Language Model' if explainer.explanation_model else 'Clinical Analysis',
            'participants_processed': 0
        },
        'explanations': []
    }
    
    test_results = model_results.get('test_results', [])[:max_participants]
    
    for result in test_results:
        participant_id = result['participant_id']
        
        # Find participant data
        participant_data = None
        for p in participants:
            if p.get('participant_id') == participant_id:
                participant_data = p
                break
        
        if not participant_data:
            continue
        
        print(f"üîç Generating AI explanation for {participant_id}...")
        
        # Generate dynamic explanation
        explanation = explainer.generate_explanation(participant_data, result)
        research_results['explanations'].append(explanation)
        
        print(f"   ‚úÖ Generated using {explanation['generation_method']}")
    
    research_results['metadata']['participants_processed'] = len(research_results['explanations'])
    
    # Save results
    output_file = "results/research_ai_explanations.json"
    with open(output_file, 'w') as f:
        json.dump(research_results, f, indent=2, default=str)
    
    print(f"\nüìä RESEARCH RESULTS:")
    print(f"Participants processed: {len(research_results['explanations'])}")
    print(f"AI Model available: {'‚úÖ' if explainer.explanation_model else '‚ùå'}")
    print(f"Results saved to: {output_file}")
    
    # Show sample
    if research_results['explanations']:
        sample = research_results['explanations'][0]
        print(f"\nüìã Sample AI Explanation for {sample['participant_id']}:")
        print("-" * 50)
        
        ai_exp = sample['ai_explanations']['clinical_analysis']
        print(f"Generated by: {ai_exp['generated_by']}")
        print(f"Content: {ai_exp['content'][:200]}...")
        
        print(f"\nModel Prediction: {sample['clinical_context']['model_assessment']['predicted_risk']}")
        print(f"Confidence: {sample['clinical_context']['model_assessment']['confidence']:.1%}")
    
    return research_results

if __name__ == "__main__":
    print("üöÄ Starting Dynamic AI Explanation Generation...")
    results = process_research_explanations(max_participants=3)
    
    if results:
        print("\n‚úÖ Research explanation generation complete!")
        print("üìÅ Check results/research_ai_explanations.json for full output")
    else:
        print("‚ùå Failed to generate explanations")